{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "snpRGxi9rBIk"
   },
   "source": [
    "# Audacity WaveformToLabels Example\n",
    "\n",
    "In this notebook we will load in a [speech to text model](https://huggingface.co/facebook/s2t-medium-librispeech-asr) from Facebook using Huggingface's Transformers module/package. We will look at the necessary dependencies to serialize  a model, how to create a wrapper class for a pretrained WaveformToLabels model, and show how to save this wrapped model so that it can easily be used in Audacity. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_t_eER_7u03e"
   },
   "outputs": [],
   "source": [
    "!pip install \"torch==1.8.1\"\n",
    "!pip install \"torchaudio==0.8.0\"\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g7c5hvQ978Cq"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "import torch\n",
    "from transformers import Speech2TextForConditionalGeneration, Speech2TextProcessor\n",
    "import torchaudio\n",
    "import json\n",
    "\n",
    "# use no grad!\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These packages will be needed if you want to upload your model to Huggingface using a CLI. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a4q83Zsg_AlH"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# required for huggingface\n",
    "!sudo apt-get install git-lfs\n",
    "!git lfs install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing Labels\n",
    "If your model has a large number of labels this block of code will read in each line as a text file as a label and store it in an array. This will minimize issues when creating your model's metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readFile(fileName):\n",
    "    fileObj = open(fileName, \"r\")\n",
    "    words = fileObj.read().splitlines() \n",
    "    fileObj.close()\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = readFile('assets/vocab.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eprLiH6w8Z_c"
   },
   "source": [
    "\n",
    "## Wraping the model\n",
    "We need to create a `.pt` containing the model itself, and a json string with the model's metadata. This meta data will tell end users about the model's domain, sample rate, labels, etc..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torchaudacity` provides a [`WaveformToLabels` class](https://github.com/hugofloresgarcia/torchaudacity/blob/main/torchaudacity/core.py#L52). We will use this as a base class for our pretrained models wrapper. The `WaveformToLabels` class provides us with tests to ensure that our model is receiving properly sized input, and outputting the expected tensor shapes for Audacity's Deep Learning Analyzer, for a [graphical explination visit the main README here](https://github.com/hugofloresgarcia/torchaudacity#contributing-models-to-audacity). \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hJdsAR_uNEQ0"
   },
   "outputs": [],
   "source": [
    "from torchaudacity import WaveformToLabels\n",
    "\n",
    "class model_wrapper(WaveformToLabels):\n",
    "    def __init__(self):\n",
    "        super().__init__(model_wrapper)\n",
    "        self._model = Speech2TextForConditionalGeneration.from_pretrained(\"facebook/s2t-medium-librispeech-asr\", torchscript=True)\n",
    "        self._processor = Speech2TextProcessor.from_pretrained(\"facebook/s2t-medium-librispeech-asr\", torchscript=True)\n",
    "    def do_forward_pass(self, input):\n",
    "        input_features = self._processor(\n",
    "        input[0],\n",
    "        sampling_rate=16_000,\n",
    "        return_tensors=\"pt\").input_features\n",
    "\n",
    "        # get predictions, and decode them\n",
    "        generated_ids = self._model.generate(input_ids=input_features)\n",
    "        transcription = self._processor.tokenizer.batch_decode(generated_ids)[0].split(' ')\n",
    "        num_preds = len(transcription)\n",
    "\n",
    "        # model predictions must be logits or one-hot encoded \n",
    "        preds_onehot = torch.FloatTensor(num_preds, 10000)\n",
    "        preds_onehot.zero_()\n",
    "        for i, token in enumerate(transcription):\n",
    "            print(token)\n",
    "            if token in self._processor.tokenizer.get_vocab():\n",
    "                token_idx = self._processor.tokenizer.get_vocab()[token]\n",
    "                preds_onehot[i][token_idx] = 1\n",
    "            elif '_' + token in self._processor.tokenizer.get_vocab():\n",
    "                token_idx = self._processor.tokenizer.get_vocab()['_' + token]\n",
    "                preds_onehot[i][token_idx] = 1\n",
    "        \n",
    "        # this model does not use timestamps, therefore we will use \n",
    "        # equally sized time ranges for each prediction\n",
    "        total_time = input.shape[1] / 16000\n",
    "        equal_size_timestamp = total_time / num_preds\n",
    "        timestamps = torch.FloatTensor(num_preds, 2)\n",
    "        timestamps.zero_()\n",
    "        for i in range(num_preds):\n",
    "            if i == 0:\n",
    "                timestamps[0][1] = equal_size_timestamp\n",
    "            else:\n",
    "                timestamps[i][0] = timestamps[i-1][1]\n",
    "                timestamps[i][1] = timestamps[i][0] + equal_size_timestamp\n",
    "\n",
    "        # return the predictions and timestamps as a tensor\n",
    "        return (preds_onehot, timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LhuyNynU21VM"
   },
   "outputs": [],
   "source": [
    "torchscript_model = model_wrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_input = torch.randn((1, 64000*64))\n",
    "torchscript_model(dummy_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "25Nl_IuaChYu"
   },
   "source": [
    "## Model Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GSpBRRjZCj1U"
   },
   "source": [
    "We need to create a `metadata.json` file for our model. This file will be added to the Huggingface repo and will provide Audacity with important information about our model. This allows for users to quickly get important information about this model directly from Audacity. See the [contributing documentation](https://github.com/hugofloresgarcia/torchaudacity) for the full metadata schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MGJaAX7QCd4W"
   },
   "outputs": [],
   "source": [
    "# create a dictionary with model metadata\n",
    "metadata = {\n",
    "    'sample_rate': 16000, \n",
    "    'domain_tags': ['speech'],\n",
    "    'short_description': 'I will label your speech into text :]',\n",
    "    'long_description': \n",
    "              'This is an Audacity wrapper for the model, '\n",
    "              'forked from the repository '\n",
    "              'facebook/s2t-medium-librispeech-asr'\n",
    "              'This model was trained by Changhan Wang'\n",
    "              'and Yun Tang and Xutai Ma and Anne Wu' \n",
    "              'and Dmytro Okhonko and Juan Pino.',\n",
    "    'tags': ['speech-to-text'],\n",
    "    'effect_type': 'waveform-to-labels',\n",
    "    'multichannel': False,\n",
    "    'labels': list(torchscript_model._processor.tokenizer.get_vocab().keys()),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Our Model & Metadata\n",
    "\n",
    "We will now save the wrapped model locally by tracing it with torchscript, and generating a `ScriptModule` or `ScriptFunction` using `torch.jit.script`. We can then use `torchaudacity's` utility function `save_model` to save the model and meta data easily. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_HKQspnf_hJM"
   },
   "outputs": [],
   "source": [
    "from torchaudacity.utils import save_model\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "In-r4gJlE-H9"
   },
   "outputs": [],
   "source": [
    "# compiling and saving model\n",
    "dummy_input = torch.randn((1, 64000*64)) # dummy input for model tracing\n",
    "traced_model = torch.jit.trace(torchscript_model, dummy_input)\n",
    "#serialized_model = torch.jit.script(traced_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(traced_model, metadata, Path('audacity-s2t-medium'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload your model\n",
    "Now you're ready to upload your model, in the case of this note book the model is stored in a folder titled 'audacity-s2t-medium'. For more information see [the main README](https://github.com/hugofloresgarcia/torchaudacity#exporting-to-huggingface) "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "labeler.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
