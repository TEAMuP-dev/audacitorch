{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "snpRGxi9rBIk"
   },
   "source": [
    "# Audacity WaveformToLabels Example\n",
    "\n",
    "In this notebook we will load in a speech to text model from Facebook using Huggingface's Transformers module/package. We will look at the necessary dependencies to serialize  a model, how to create a wrapper class for a pretrained WaveformToLabels model, and show how to save this wrapped model so that it can easily be used in Audacity. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "_t_eER_7u03e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch==1.8.1\n",
      "  Using cached torch-1.8.1-cp39-cp39-win_amd64.whl (190.5 MB)\n",
      "Requirement already satisfied: numpy in c:\\users\\aldo\\miniconda3\\envs\\audacity\\lib\\site-packages (from torch==1.8.1) (1.21.2)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\aldo\\miniconda3\\envs\\audacity\\lib\\site-packages (from torch==1.8.1) (3.10.0.2)\n",
      "Installing collected packages: torch\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.8.0\n",
      "    Uninstalling torch-1.8.0:\n",
      "      Successfully uninstalled torch-1.8.0\n",
      "Successfully installed torch-1.8.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchaudio 0.8.0 requires torch==1.8.0, but you have torch 1.8.1 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchaudio==0.8.0 in c:\\users\\aldo\\miniconda3\\envs\\audacity\\lib\\site-packages (0.8.0)\n",
      "Collecting torch==1.8.0\n",
      "  Using cached torch-1.8.0-cp39-cp39-win_amd64.whl (190.5 MB)\n",
      "Requirement already satisfied: numpy in c:\\users\\aldo\\miniconda3\\envs\\audacity\\lib\\site-packages (from torch==1.8.0->torchaudio==0.8.0) (1.21.2)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\aldo\\miniconda3\\envs\\audacity\\lib\\site-packages (from torch==1.8.0->torchaudio==0.8.0) (3.10.0.2)\n",
      "Installing collected packages: torch\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.8.1\n",
      "    Uninstalling torch-1.8.1:\n",
      "      Successfully uninstalled torch-1.8.1\n",
      "Successfully installed torch-1.8.0\n",
      "Requirement already satisfied: transformers in c:\\users\\aldo\\miniconda3\\envs\\audacity\\lib\\site-packages (4.10.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\aldo\\miniconda3\\envs\\audacity\\lib\\site-packages (from transformers) (1.21.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\aldo\\miniconda3\\envs\\audacity\\lib\\site-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: filelock in c:\\users\\aldo\\miniconda3\\envs\\audacity\\lib\\site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: huggingface-hub>=0.0.12 in c:\\users\\aldo\\miniconda3\\envs\\audacity\\lib\\site-packages (from transformers) (0.0.17)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\aldo\\miniconda3\\envs\\audacity\\lib\\site-packages (from transformers) (2021.8.28)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\aldo\\miniconda3\\envs\\audacity\\lib\\site-packages (from transformers) (4.62.3)\n",
      "Requirement already satisfied: requests in c:\\users\\aldo\\miniconda3\\envs\\audacity\\lib\\site-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\aldo\\miniconda3\\envs\\audacity\\lib\\site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in c:\\users\\aldo\\miniconda3\\envs\\audacity\\lib\\site-packages (from transformers) (0.10.3)\n",
      "Requirement already satisfied: sacremoses in c:\\users\\aldo\\miniconda3\\envs\\audacity\\lib\\site-packages (from transformers) (0.0.45)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\aldo\\miniconda3\\envs\\audacity\\lib\\site-packages (from huggingface-hub>=0.0.12->transformers) (3.10.0.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\aldo\\miniconda3\\envs\\audacity\\lib\\site-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\aldo\\miniconda3\\envs\\audacity\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\aldo\\miniconda3\\envs\\audacity\\lib\\site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\aldo\\miniconda3\\envs\\audacity\\lib\\site-packages (from requests->transformers) (2021.5.30)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\aldo\\miniconda3\\envs\\audacity\\lib\\site-packages (from requests->transformers) (1.25.11)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\aldo\\miniconda3\\envs\\audacity\\lib\\site-packages (from requests->transformers) (4.0.0)\n",
      "Requirement already satisfied: click in c:\\users\\aldo\\miniconda3\\envs\\audacity\\lib\\site-packages (from sacremoses->transformers) (8.0.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\aldo\\miniconda3\\envs\\audacity\\lib\\site-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: six in c:\\users\\aldo\\miniconda3\\envs\\audacity\\lib\\site-packages (from sacremoses->transformers) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install \"torch==1.8.1\"\n",
    "!pip install \"torchaudio==0.8.0\"\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "g7c5hvQ978Cq"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "import torch\n",
    "from transformers import Speech2TextForConditionalGeneration, Speech2TextProcessor\n",
    "import torchaudio\n",
    "import json\n",
    "\n",
    "# use no grad!\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These packages will be needed if you want to upload your model to Huggingface using a CLI. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "a4q83Zsg_AlH"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# required for huggingface\n",
    "!sudo apt-get install git-lfs\n",
    "!git lfs install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing Labels\n",
    "If your model has a large number of labels this block of code will read in each line as a text file as a label and store it in an array. This will minimize issues when creating your model's metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readFile(fileName):\n",
    "    fileObj = open(fileName, \"r\")\n",
    "    words = fileObj.read().splitlines() \n",
    "    fileObj.close()\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = readFile('assets/vocab.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eprLiH6w8Z_c"
   },
   "source": [
    "\n",
    "## Wraping the model\n",
    "We need to create a `.pt` containing the model itself, and a json string with the model's metadata. This meta data will tell end users about the model's domain, sample rate, labels, etc..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torchaudacity` provides a `WaveformToLabels` class. We will use this as a base class for our pretrained models wrapper. The `WaveformToLabels` class provides us with tests to ensure that our model is receiving properly sized input, and outputting the expected tensor shapes for Audacity's Deep Learning Analyzer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "hJdsAR_uNEQ0"
   },
   "outputs": [],
   "source": [
    "from torchaudacity import WaveformToLabels\n",
    "\n",
    "class model_wrapper(WaveformToLabels):\n",
    "    def __init__(self, model, processor, vocab):\n",
    "        super().__init__(model_wrapper)\n",
    "        self._model = model\n",
    "        self._processor = processor\n",
    "    def do_forward_pass(self, input):\n",
    "        input_features = self._processor(\n",
    "        input[0],\n",
    "        sampling_rate=16_000,\n",
    "        return_tensors=\"pt\"\n",
    "        ).input_features\n",
    "\n",
    "        # get predictions, and decode them\n",
    "        generated_ids = self._model.generate(input_ids=input_features)\n",
    "        transcription = processor.tokenizer.batch_decode(generated_ids)[0].split(' ')\n",
    "        num_preds = len(transcription)\n",
    "\n",
    "        # model predictions must be logits or one-hot encoded \n",
    "        preds_onehot = torch.FloatTensor(num_preds, 10000)\n",
    "        preds_onehot.zero_()\n",
    "        for i, token in enumerate(transcription):\n",
    "            if token in processor.tokenizer.get_vocab():\n",
    "                token_idx = processor.tokenizer.get_vocab()[token]\n",
    "                preds_onehot[i][token_idx] = 1\n",
    "            elif '_' + token in processor.tokenizer.get_vocab():\n",
    "                token_idx = processor.tokenizer.get_vocab()['_' + token]\n",
    "                preds_onehot[i][token_idx] = 1\n",
    "            else:\n",
    "                preds_onehot[i][3] = 1\n",
    "        \n",
    "        # this model does not use timestamps, therefore we will use \n",
    "        # equally sized time ranges for each prediction\n",
    "        total_time = input.shape[1] / 16000\n",
    "        equal_size_timestamp = total_time / num_preds\n",
    "        timestamps = torch.FloatTensor(num_preds, 2)\n",
    "        timestamps.zero_()\n",
    "        for i in range(num_preds):\n",
    "            if i == 0:\n",
    "                timestamps[0][1] = equal_size_timestamp\n",
    "            else:\n",
    "                timestamps[i][0] = timestamps[i-1][1]\n",
    "                timestamps[i][1] = timestamps[i][0] + equal_size_timestamp\n",
    "\n",
    "        # return the predictions and timestamps as a tensor\n",
    "        return (preds_onehot, timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "LhuyNynU21VM"
   },
   "outputs": [],
   "source": [
    "model = Speech2TextForConditionalGeneration.from_pretrained(\"facebook/s2t-medium-librispeech-asr\", torchscript=True)\n",
    "processor = Speech2TextProcessor.from_pretrained(\"facebook/s2t-medium-librispeech-asr\")\n",
    "model.eval()\n",
    "\n",
    "torchscript_model = model_wrapper(model, processor, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       " tensor([[0., 1.],\n",
       "         [1., 2.]]))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_input = torch.randn((1, 32000))\n",
    "torchscript_model(dummy_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "25Nl_IuaChYu"
   },
   "source": [
    "## Model Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GSpBRRjZCj1U"
   },
   "source": [
    "We need to create a `metadata.json` file for our model. This file will be added to the Huggingface repo and will provide Audacity with important information about our model. This allows for users to quickly get important information about this model directly from Audacity. See the [contributing documentation](https://github.com/hugofloresgarcia/torchaudacity) for the full metadata schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "MGJaAX7QCd4W"
   },
   "outputs": [],
   "source": [
    "# create a dictionary with model metadata\n",
    "metadata = {\n",
    "    'sample_rate': 16000, \n",
    "    'domain_tags': ['speech'],\n",
    "    'short_description': 'I will label your speech into text :]',\n",
    "    'long_description': \n",
    "              'This is an Audacity wrapper for the model, '\n",
    "              'forked from the repository '\n",
    "              'facebook/s2t-medium-librispeech-asr'\n",
    "              'This model was trained by Changhan Wang'\n",
    "              'and Yun Tang and Xutai Ma and Anne Wu' \n",
    "              'and Dmytro Okhonko and Juan Pino.',\n",
    "    'tags': ['speech-to-text'],\n",
    "    'effect_type': 'waveform-to-labels',\n",
    "    'multichannel': False,\n",
    "    'labels': list(processor.tokenizer.get_vocab().keys()),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Our Model & Metadata\n",
    "\n",
    "We will now save the wrapped model locally by tracing it with torchscript, and generating a `ScriptModule` or `ScriptFunction` using `torch.jit.script`. We can then use `torchaudacity's` utility function `save_model` to save the model and meta data easily. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "_HKQspnf_hJM"
   },
   "outputs": [],
   "source": [
    "from torchaudacity.utils import save_model\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "In-r4gJlE-H9"
   },
   "outputs": [],
   "source": [
    "# compiling and saving model\n",
    "dummy_input = torch.randn((1, 2048)) # dummy input for model tracing\n",
    "traced_model = torch.jit.trace(torchscript_model, dummy_input)\n",
    "serialized_model = torch.jit.script(traced_model)\n",
    "\n",
    "save_model(serialized_model, metadata, Path('audacity-s2t-medium'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "labeler.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
