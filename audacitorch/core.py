from typing import Tuple, List, Optional, Type, Any, Dict
import torch
from torch import nn

def _waveform_check(x: torch.Tensor):
  assert x.ndim == 2, "input must have two dimensions (channels, samples)"
  assert x.shape[-1] > x.shape[0], f"The number of channels {x.shape[-2]} exceeds the number of samples {x.shape[-1]} in your INPUT waveform. \
                                      There might be something wrong with your model. "

def _param_check(params: torch.Tensor):
  """check the parameters match a spec we have in our attributes"""
  # NOT IMPLEMENTED
  pass

class Parameter:
  pass

def get_list_type(lst: List[Any]) -> Type:
    """generated by gpt4"""
    if not lst:  # If the list is empty
        return List[Any]  # We can't infer anything about its contents
    if all(isinstance(i, type(lst[0])) for i in lst):  # If all elements have the same type
        return List[type(lst[0])]  # Return this type
    return List[Any]  # If there are different types, return the most generic type

def get_dict_types(d: Dict[Any, Any]) -> Tuple[Type, Type]:
    """generated by gpt4"""
    if not d:  # If the dictionary is empty
        return Dict[Any, Any]  # We can't infer anything about its contents

    # Collect the types of the keys and the values
    key_type = value_type = None

    for key, value in d.items():
        if key_type is None:
            key_type = type(key)
        if value_type is None:
            value_type = type(value)

        # If we find a key or a value of a different type, we'll return a generic dict
        if not isinstance(key, key_type) or not isinstance(value, value_type):
            return Dict[Any, Any]

    return Dict[key_type, value_type]


class AudacityModel(torch.jit.ScriptModule):
  sample_rate: int
  name: str
  author: str
  description: str
  tags: List[str]
  
  def __init__(self, model: nn.Module, metadata: dict):
    """ creates an Audacity model, wrapping a child model (that does the real work)"""
    super().__init__()
    model.eval()
    self.model = model

    self.register_attributes(metadata)

  @torch.jit.ignore
  def _validate_builtins(self, metadata: dict):
    assert "sample_rate" in metadata, "metadata must contain a sample_rate"
    assert isinstance(metadata["sample_rate"], int), "sample_rate must be an integer"
    assert metadata["sample_rate"] > 0, "sample_rate must be greater than 0"

    def _validate_string(meta: dict, key: str):
      assert key in meta, f"metadata must contain {key}"
      assert isinstance(meta[key], str), f"{key} must be a string"
      assert len(meta[key]) > 0, f"{key} must not be empty"

    _validate_string(metadata, "name")
    _validate_string(metadata, "author")
    _validate_string(metadata, "description")
    
    assert "tags" in metadata, "metadata must contain tags"
    assert isinstance(metadata["tags"], List), "tags must be a list"
    assert len(metadata["tags"]) > 0, "tags must not be empty"
    assert all([isinstance(t, str) for t in metadata["tags"]]), "tags must be a list of strings"

  @torch.jit.ignore
  def register_attributes(self, metadata: dict):
    # validate the builtins first
    self._validate_builtins(metadata)

    for attr_key, attr_val in metadata.items():

      attr_type= type(attr_val)

      if isinstance(attr_val, Parameter): 
        raise NotImplementedError
      elif attr_type == list:
        attr_type = get_list_type(attr_val)
      elif attr_type == dict:
        attr_type = get_dict_types(attr_val)

      setattr(self, attr_key, torch.jit.Attribute(attr_val, attr_type)) 
    

class WaveformToWaveformBase(AudacityModel):

  def forward(self, x: torch.Tensor, params: Optional[torch.Tensor] = None) -> torch.Tensor:
    """ 
    Internal forward pass for a WaveformToWaveform model. 

    All this does is wrap the do_forward_pass(x) function in assertions that check 
    that the correct input/output constraints are getting met. Nothing fancy. 
    """
    _waveform_check(x)
    x = self.do_forward_pass(x, params)
    _waveform_check(x)
    
    return x

  def do_forward_pass(self, x: torch.Tensor, params: Optional[torch.Tensor] = None) -> torch.Tensor:
    """ 
    Perform a forward pass on a waveform-to-waveform model.
    
    Args:
        x : An input audio waveform tensor. If `"multichannel" == True` in the 
            model's `metadata.json`, then this tensor will always be shape 
            `(1, n_samples)`, as all incoming audio will be downmixed first. 
            Otherwise, expect `x` to be a multichannel waveform tensor with 
            shape `(n_channels, n_samples)`.

    Returns:
        torch.Tensor: Output tensor, shape (n_sources, n_samples). Each source 
                      will be  
    """
    raise NotImplementedError("implement me!")

class WaveformToLabelsBase(AudacityModel):

  def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:
    """ 
    Internal forward pass for a WaveformToLabels model. 

    All this does is wrap the do_forward_pass(x) function in assertions that check 
    that the correct input/output constraints are getting met. Nothing fancy. 
    """
    _waveform_check(x)
    output = self.do_forward_pass(x)

    assert isinstance(output, tuple), "waveform-to-labels output must be a tuple"
    assert len(output) == 2, "output tuple must have two elements, e.g. tuple(labels, timestamps)"

    labels = output[0]
    timestamps = output[1]

    assert torch.all(timestamps >= 0).item(), f"found a timestamp that is less than zero"

    for timestamp in timestamps:
      assert timestamp[0] < timestamp[1], f"timestamp ends ({timestamp[1]}) before it starts ({timestamp[0]})"

    assert labels.ndim == 1, "labels tensor should be one dimensional"

    assert labels.shape[0] == timestamps.shape[0], "time dimension between "\
                                    "labels and timestamps tensors must be equal"
    assert timestamps.shape[1] == 2, "second dimension of the timestamps tensor"\
                                      "must be size 2"
    return output

  def do_forward_pass(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:
    """ 
    Perform a forward pass on a waveform-to-labels model.
    
    Args:
        x : An input audio waveform tensor. If `"multichannel" == True` in the 
            model's `metadata.json`, then this tensor will always be shape 
            `(1, n_samples)`, as all incoming audio will be downmixed first. 
            Otherwise, expect `x` to be a multichannel waveform tensor with 
            shape `(n_channels, n_samples)`.

    Returns:
        Tuple[torch.Tensor, torch.Tensor]: a tuple of tensors, where the first 
            tensor contains the output class probabilities 
            (shape `(n_timesteps, n_labels)`), and the second tensor contains 
            timestamps with start and end times for each label, 
            shape `(n_timesteps, 2)`. 

    """
    raise NotImplementedError("implement me!")
